/*
Cortex-M85 example

Copyright (c) 2020-2022 Arm Limited (or its affiliates). All rights reserved.
Use, modification and redistribution of this file is subject to your possession of a
valid End User License Agreement for the Arm Product of which these examples are part of
and your compliance with all applicable terms and conditions of such licence agreement.
*/

#include <stdio.h>
#include <stdint.h>
#include <arm_mve.h>

extern void pacbti_asm_demo(void); // Assembler example
extern void compare_sorts(void);   // C code example


/* Helper function to create a vector of 4 floats */
static inline float32x4_t make_vector_of_floats(float a, float b,
                                                float c, float d)
{
    union { float f[2]; uint64_t u; } w[2];

    w[0].f[0] = a;
    w[0].f[1] = b;
    w[1].f[0] = c;
    w[1].f[1] = d;

    return vcreateq_f32(w[0].u, w[1].u);
}

/* Arrays to show auto-vectorization using MVE instructions,
   and low-overhead loop instructions being generated by the compiler.
 */
short a[64];
short b[64];

void init_arrays(void)
{
    short i;

    for(i=0; i<64; i++)
    {
        a[i] = i;
        b[i] = i;
    }

    return;
}

/* Example of a multiply-accumulate (MLA) function
   that can be auto-vectorized by the compiler.
   The compiler can also generate low-overload loop
   instructions for the loop within this function.
 */
__attribute__((noinline)) int mla(void)
{
    short i;
    int sum = 0;

    for(i=0; i<64; i++)
    {
        sum += a[i] * b[i];
    }

    return sum;
}


/* Arrays to demonstrate sum of products */
unsigned char p[] = { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 };
unsigned char q[] = { 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1 ,0 };


/* The following three test functions all load 16 bytes from the two arrays 'p' and 'q',
   and return a sum of the products of corresponding elements of these arrays, in three different ways */

/* Sum of products (inline assembler) using vmul/vaddv.
   Needs a temporary intermediate register q2.
   The vaddv instruction requires an even-numbered output register, so use "=Te"
   to force the compiler's register allocator to choose an even-numbered register */
uint32_t test1(unsigned char *a, unsigned char *b)
{
    uint32_t sum = 0;

    __asm volatile(
        "vldrb.u8 q0, [%[ptr_a]]\n"
        "vldrb.u8 q1, [%[ptr_b]]\n"
        "vmul.u8  q2, q1, q0\n"
        "vaddv.u8 %[output], q2\n"
        : [output] "=Te" (sum)
        : [ptr_a] "r" (a), [ptr_b] "r" (b)
        : "q0", "q1", "q2"
    );

    return sum;
}

/* Sum of products (inline assembler) using vmladav.
   Does not need a temporary intermediate register.
   The vmladav instruction requires an even-numbered output register, so use "=Te"
   to force the compiler's register allocator to choose an even-numbered register */
uint32_t test2(unsigned char *a, unsigned char *b)
{
    uint32_t sum = 0;

    __asm volatile(
        "vldrb.u8 q0, [%[ptr_a]]\n"
        "vldrb.u8 q1, [%[ptr_b]]\n"
        "vmladav.u8 %[output], q0, q1\n"
        : [output] "=Te" (sum)
        : [ptr_a] "r" (a), [ptr_b] "r" (b)
        : "q0", "q1"
    );

    return sum;
}

/* Sum of products (compiler intrinsics) */
uint32_t test3(unsigned char *a, unsigned char *b)
{
    uint8x16_t vec_a, vec_b;

    vec_a = __arm_vldrbq_u8(a);
    vec_b = __arm_vldrbq_u8(b);
    return __arm_vmladavq_u8(vec_a, vec_b);
}

/* vmulq() intrinsic deliberately factored out to subvert compiler optimization */
__attribute__((noinline)) float32x4_t do_vmulq(float32x4_t vf1, float32x4_t vf2)
{
	return vmulq(vf1, vf2);
}


/* Vectors of floats to demonstrate vector floating-point multiplication */
float32x4_t vf1, vf2, vf3;


__attribute__((noreturn)) int main(void)
{
    printf("\nCortex-M85 example\n");

    printf("\n1. Multiply-Accumulate (MLA):\n");
	init_arrays();
	printf("MLA result (sum of the squares from 0 to 63) is: %d\n\n", mla());

    printf("\n2. Vector floating-point multiplication using MVE intrinsics:\n");
	/* Create structures with values to use */
    vf1 = make_vector_of_floats(0.1, 0.2, 0.3, 0.4);
    vf2 = make_vector_of_floats(0.5, 0.6, 0.7, 0.8);

	/* Use intrinsics to do 4 parallel floating-point multiplications: vf3 = vf1 * vf2 */
	vf3 = do_vmulq(vf1, vf2);

	printf("[%1.2f, %1.2f, %1.2f, %1.2f]\n",
		vgetq_lane(vf1, 0), vgetq_lane(vf1, 1), vgetq_lane(vf1, 2), __arm_vgetq_lane(vf1, 3));
	printf("            *\n");
	printf("[%1.2f, %1.2f, %1.2f, %1.2f]\n",
		vgetq_lane(vf2, 0), vgetq_lane(vf2, 1), vgetq_lane(vf2, 2), vgetq_lane(vf2, 3));
	printf("            =\n");
	printf("[%1.2f, %1.2f, %1.2f, %1.2f]\n\n",
		vgetq_lane(vf3, 0), vgetq_lane(vf3, 1), vgetq_lane(vf3, 2), vgetq_lane(vf3, 3));

    printf("\n3. Sum of products in three ways:\n");
    printf("Sum of products (inline assembler vmul/vaddv) = %d\n", test1( p, q ));
    printf("Sum of products (inline assembler vmladav)    = %d\n", test2( p, q ));
    printf("Sum of products (compiler intrinsics)         = %d\n", test3( p, q ));
    printf("Result of all tests should be                 = 560\n");

    printf("\n4. Demo PAC and BTI (separately) in assembler...\n");
    pacbti_asm_demo();  // Assembler example

    printf("\n5. Demo PACBTI added automatically in C code...\n");
    compare_sorts();    // C code example

    printf("\n6. HardFault trigger/handler:\n");
    printf("This will fault...\n");

    __asm volatile("udf #0");

    /* Should never reach here */
    while( 1 )
    {
        /* Loop forever */
    }
}

